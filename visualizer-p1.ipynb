{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.multiprocessing as _mp\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "import resnet_cifar10\n",
    "from networks import NetDelta, NetTMR, NetDMR, NetTMROutput\n",
    "from utils import *\n",
    "\n",
    "import copy\n",
    "import time\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import sysconfig\n",
    "print(sysconfig.get_paths()['include'])\n",
    "\n",
    "device = torch.device(\"cpu\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print('Using device :', device)\n",
    "#Additional Info when using cuda\n",
    "if device.type == 'cuda':\n",
    "    print('GPU          :', torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    import cpuinfo\n",
    "    print(\"CPU          :\", cpuinfo.get_cpu_info()['brand_raw'])\n",
    "\n",
    "print(\"Pytorch version: \",torch.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))])\n",
    "\n",
    "test_set = datasets.CIFAR10(\"cifar10\", train=False, download=True, transform=test_transform)\n",
    "\n",
    "testloaders = torch.utils.data.DataLoader(test_set, batch_size=256, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_time = 20"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_types = [20,32,44,56]\n",
    "idss =        [[0, 302], [0,346],[0,365],[0,368]]\n",
    "base_times = []\n",
    "\n",
    "# base\n",
    "for id, mod in zip(idss, model_types):\n",
    "    models = []\n",
    "    ids = id\n",
    "    model_name =\"resnet\"+str(mod)\n",
    "    models_path = \"resnet_models/\"\n",
    "\n",
    "    # load all models\n",
    "    models = eval_model_load(str(mod), ids, model_name, models_path, compile=False)\n",
    "    print(evaluate_acc(models[0], testloaders))\n",
    "    evaluate_acc(models[0], testloaders, single=True, time_profiler=True)\n",
    "    print(\"finish warming up..\")\n",
    "    model_time = []\n",
    "    for i in range(run_time):\n",
    "        model_time.append(evaluate_acc(models[0], testloaders, single=True, time_profiler=True)[-1])\n",
    "    base_times.append(model_time)\n",
    "    # break\n",
    "print(base_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meantime = 0.\n",
    "for _ in range(10):\n",
    "    sample_input= next(iter(testloaders))[0][0].unsqueeze(0).to(device)\n",
    "    if device == \"cuda\": \n",
    "        torch.cuda.synchronize()\n",
    "    # with torch.no_grad():\n",
    "    startdmr = time.perf_counter()\n",
    "    models[0](sample_input)\n",
    "    if device == \"cuda\": \n",
    "        torch.cuda.synchronize()\n",
    "    enddmr = time.perf_counter()\n",
    "    meantime += (enddmr-startdmr)*1000\n",
    "meantime /= 10\n",
    "print(\"mean time: \", meantime)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_types = [20,32,44,56]\n",
    "idss =        [[0, 302], [0,346],[0,365],[0,368]]\n",
    "TMR_times = []\n",
    "TMR_times2 = []\n",
    "\n",
    "\n",
    "for id, mod in zip(idss, model_types):\n",
    "    models = []\n",
    "    ids = id\n",
    "    model_name =\"resnet\"+str(mod)\n",
    "    models_path = \"resnet_models/\"\n",
    "\n",
    "    # load all models\n",
    "    models = eval_model_load(str(mod), ids, model_name, models_path, compile=False)\n",
    "    print(evaluate_acc(models[0], testloaders))\n",
    "\n",
    "    modelTMR = NetTMR(models[0])\n",
    "    modelTMR.to(device)\n",
    "    modelTMR.eval()\n",
    "    print(\"model TMR ready\")\n",
    "    print(\"accuracy\", evaluate_acc(modelTMR, testloaders))\n",
    "\n",
    "    evaluate_acc(modelTMR, testloaders, single=True, time_profiler=True)\n",
    "    print(\"finish warming up..\")\n",
    "    model_time = []\n",
    "    modelTMR.protected=True\n",
    "    # modelTMR.detection_time = True #########\n",
    "    for i in range(run_time):\n",
    "        # modelTMR.resetTime()\n",
    "        model_time.append(evaluate_acc(modelTMR, testloaders, single=True, time_profiler=True)[-1])\n",
    "    TMR_times.append(model_time)\n",
    "    # TMR_times2.append(np.sum(modelTMR.list_detection_time)) #########\n",
    "#     break #########\n",
    "# print(TMR_times)\n",
    "# print(np.mean(TMR_times2)) #########"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TMR Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_types = [20,32,44,56]\n",
    "idss =        [[0, 302], [0,346],[0,365],[0,368]]\n",
    "TMRo_times = []\n",
    "TMRo_times2 = []\n",
    "\n",
    "for id, mod in zip(idss, model_types):\n",
    "    models = []\n",
    "    ids = id\n",
    "    model_name =\"resnet\"+str(mod)\n",
    "    models_path = \"resnet_models/\"\n",
    "\n",
    "    # load all models\n",
    "    models = eval_model_load(str(mod), ids, model_name, models_path, compile=False)\n",
    "    print(evaluate_acc(models[0], testloaders))\n",
    "\n",
    "    modelTMRo = NetTMROutput(models[0])\n",
    "    modelTMRo.to(device)\n",
    "    modelTMRo.eval()\n",
    "    print(\"model TMR ready\")\n",
    "    print(\"accuracy\", evaluate_acc(modelTMRo, testloaders))\n",
    "\n",
    "    evaluate_acc(modelTMRo, testloaders, single=True, time_profiler=True)\n",
    "    print(\"finish warming up..\")\n",
    "    model_time = []\n",
    "    modelTMRo.protected=True\n",
    "    # modelTMRo.detection_time = True #########\n",
    "    for i in range(run_time):\n",
    "        # modelTMRo.resetTime()\n",
    "        model_time.append(evaluate_acc(modelTMRo, testloaders, single=True, time_profiler=True)[-1])\n",
    "    TMRo_times.append(model_time)\n",
    "    # TMRo_times2.append(np.sum(modelTMRo.list_detection_time)) #########\n",
    "#     break #########\n",
    "print(TMRo_times)\n",
    "# print(np.mean(TMRo_times2)) #########"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_types = [20,32,44,56]\n",
    "idss =        [[0, 302], [0,346],[0,365],[0,368]]\n",
    "DMR_times = []\n",
    "DMR_times2 = []\n",
    "\n",
    "for id, mod in zip(idss, model_types):\n",
    "    models = []\n",
    "    ids = id\n",
    "    model_name =\"resnet\"+str(mod)\n",
    "    models_path = \"resnet_models/\"\n",
    "\n",
    "    # load all models\n",
    "    models = eval_model_load(str(mod), ids, model_name, models_path, compile=False)\n",
    "    print(evaluate_acc(models[0], testloaders))\n",
    "\n",
    "    modelDMR = NetDMR(models[0], \"\", sum_model(models[0]))\n",
    "    modelDMR.to(device)\n",
    "    modelDMR.eval()\n",
    "    print(\"model DMR ready\")\n",
    "    print(\"accuracy\", evaluate_acc(modelDMR, testloaders))\n",
    "\n",
    "    evaluate_acc(modelDMR, testloaders, single=True, time_profiler=True)\n",
    "    print(\"finish warming up..\")\n",
    "    model_time = []\n",
    "    modelDMR.protected=True\n",
    "    # modelDMR.detection_time = True\n",
    "    # modelDMR.recovery_time = True\n",
    "    modelDMR.debug = False\n",
    "    for i in range(run_time):\n",
    "        # modelDMR.resetTime()\n",
    "        model_time.append(evaluate_acc(modelDMR, testloaders, single=True, time_profiler=True)[-1])\n",
    "        # DMR_times2.append(np.sum(modelDMR.list_detection_time))\n",
    "    DMR_times.append(model_time)\n",
    "    # break\n",
    "print(DMR_times)\n",
    "print(\"Average of Total Inference Time (no fault)    :\", \"{:.4f}\".format(np.mean(DMR_times[0])), \"ms\")\n",
    "# print(\"Average of Total Detection Time (no fault)    :\", \"{:.4f}\".format(np.mean(DMR_times2)), \"ms\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NAPER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_types = [20,32,44,56]\n",
    "idss =        [[0, 302], [0,346],[0,365],[0,368]]\n",
    "NaPER_times = []\n",
    "# NaPER_single = []\n",
    "NaPER_times2 = []\n",
    "\n",
    "# NAPER ENSEMBLE\n",
    "for id, mod in zip(idss, model_types):\n",
    "    models = []\n",
    "    ids = id\n",
    "    model_name =\"resnet\"+str(mod)\n",
    "    models_path = \"resnet_models/\"\n",
    "\n",
    "    # load all models\n",
    "    models = eval_model_load(str(mod), ids, model_name, models_path, compile=False)\n",
    "    print(\"model 0 accuracy\", evaluate_acc(models[0], testloaders))\n",
    "\n",
    "    deltas, summs = get_sum_delta(models)\n",
    "    modelDelta = NetDelta(models, deltas, summs)\n",
    "    modelDelta.protected=False\n",
    "    # modelDelta.detection_time = True\n",
    "    print(\"model NaPER ready\")\n",
    "    print(\"ensemble accuracy\",ens_evaluate_acc(wrappermodel=modelDelta, testloaders=testloaders))\n",
    "    print(\"ensemble 0 accuracy\",ens_evaluate_acc(wrappermodel=modelDelta, testloaders=testloaders, limit_model=1))\n",
    "\n",
    "    print(\"finish warming up..\")\n",
    "    model_time = []\n",
    "    modelDelta.protected=True\n",
    "    for i in range(run_time):\n",
    "        # modelDelta.resetTime()\n",
    "        model_time.append(ens_evaluate_acc(wrappermodel=modelDelta, testloaders=testloaders, single=True, time_profiler=True)[-1])\n",
    "    NaPER_times.append(model_time)\n",
    "    # NaPER_times2.append(np.sum(modelDelta.list_detection_time))\n",
    "\n",
    "    # model_time = []\n",
    "    # for i in range(run_time):\n",
    "    #     model_time.append(ens_evaluate_acc(wrappermodel=modelDelta, testloaders=testloaders, single=True,\n",
    "    #                                        time_profiler=True, limit_model=1)[-1])\n",
    "    # NaPER_single.append(model_time)\n",
    "    # break\n",
    "print(NaPER_times)\n",
    "# print(NaPER_single)\n",
    "# print(np.mean(NaPER_times2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_types = [20,32,44,56]\n",
    "idss =        [[0, 302], [0,346],[0,365],[0,368]]\n",
    "EnsRes_time = []\n",
    "\n",
    "for id, mod in zip(idss, model_types):\n",
    "    models = []\n",
    "    ids = id\n",
    "    model_name =\"resnet\"+str(mod)\n",
    "    models_path = \"resnet_models/\"\n",
    "\n",
    "    # load all models\n",
    "    models = eval_model_load(str(mod), ids, model_name, models_path, compile=False)\n",
    "    print(evaluate_acc(models[0], testloaders))\n",
    "\n",
    "    # deltas, summs = get_sum_delta(models)\n",
    "    # modelDelta = NetDelta(models, ids, mod, deltas, summs)\n",
    "    print(\"model ensemble ready\")\n",
    "    print(\"accuracy\",ens_evaluate_acc(models=models, testloaders=testloaders))\n",
    "    ens_evaluate_acc(models=models, testloaders=testloaders, single=True, time_profiler=True)\n",
    "    ens_evaluate_acc(models=models, testloaders=testloaders, single=True, time_profiler=True)\n",
    "    print(\"finish warming up..\")\n",
    "    model_time = []\n",
    "    for i in range(run_time):\n",
    "        model_time.append(ens_evaluate_acc(models=models, testloaders=testloaders, single=True, time_profiler=True)[-1])\n",
    "    EnsRes_time.append(model_time)\n",
    "print(EnsRes_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "0fe7b43fad9edec63fa82f3f73e616d969dee4f0ed6e657c58f46f9ed683f800"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
